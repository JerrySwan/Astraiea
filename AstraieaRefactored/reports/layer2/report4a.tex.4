\documentclass[]{article}
\usepackage[usenames,dvipsnames]{color}
\usepackage{longtable}
\begin{document}

\section{Experimental Results (Thu Nov 26 01:21:26 GMT 2015)}
Experiments were performed using the \textsc{Astraiea}\footnote{This file has been automatically generated by Astraiea} statistical testing framework \cite{Neumann:2014:EET:2598394.2609850},
which performs tests in accordance with the guidelines of ``A Hitchhikers guide to statistical testing''
by Briand and Arcuri~\cite{Arcuri2012}.
Unless a different reference is given, the tests are performed as described in this paper.

Statistical testing was carried out as follows: 
This data was obtained from runs on multiple artefacts. Each artefact is treated as a single run for the purpose of statistical comparison and so, the experimental description below,  the number of runs refers to the number of artefacts. For each artefact 1 repeated tests were carried out and the median of these results was used as the result for that artefact for the purposes of subsequent statistical testing.\begin{itemize}
\item{All experiments were repeated 30 times ($n$=30)}
\item{The data is dichotomous and paired and so the Fisher test of statistical significance was used followed by the Odds Ratio test of effect size.These tests compare boolean values, denoting a pass or a fail, from the final point in the result time series. 

This data is censored, that is to say the point at which results are obtained is the arbitrary point at which the test stopped running. This may not accurately reflect the true difference between the two datasets. For this reason, additional statistical tests were carried out if this initial test did not show significance. Additional tests where carried out in this order:
\begin{itemize}
\item{0: Tests were run using an artificial censoring point at point -1 in the time series.}
\item{1: Tests were run using an artificial censoring point at point 50 in the time series.}
\end{itemize}Note that using these strategies involves multiple P value calculations on the same data. This should be taken into account when interpreting these results.
}
\end{itemize}A complete list of p value tests carried out is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{3}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{3}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 30. An intermediate, artificial censoring point was used of 50.

The final results from comparing null and null are as follows:
\begin{itemize}
\item{data is not significant (p value of 0.9999999999999929, threshold of 0.05)}
\end{itemize}Statistical testing was carried out as follows: 
This data was obtained from runs on multiple artefacts. Each artefact is treated as a single run for the purpose of statistical comparison and so, the experimental description below,  the number of runs refers to the number of artefacts. For each artefact 1 repeated tests were carried out and the median of these results was used as the result for that artefact for the purposes of subsequent statistical testing.\begin{itemize}
\item{Using the process of incrementing the number of runs until the difference is statistically significant. Initially 20 experiments were run. If sigificance is not obtained from these experiments then additional experiments are run until either significance is obtained or a maximum of 100 experiments have been run. When this technique is used effect size testing is especially important as a number of samples sufficient to show a statistically significant difference is likely to be reached even if the difference is too small to be useful. Note that this strategy involves multiple P value calculations as $n$ increases. These have not been adjusted and issues related to multiple testing should be taken into account when interpreting these results.
}
\item{The Wilcoxon/ Mann Whitney U Significance Test was used.}
\item{The Vargha Delaney Effect Size Test was used. Effect size testing is essential in addition to significance testing as it demonstrates the magnitude of the difference between two samples. With a large enough number of experiments (large enough $n$), the results of two different generating techniques are likely to be different to a statistically significant extent. Effect size testing is needed to show that this difference is useful.}
\end{itemize}A complete list of p value tests carried out is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{3}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{3}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 100. 

The final results from comparing null and null are as follows:
\begin{itemize}
\item{difference is significant (p value of 0.006174550948616964, threshold of 0.05)}
\item{the effect size is 0.3879, confidence intervals (obtained by bootstrapping)= 0.30995 - 0.468695}
\item{null is lower than null}
\end{itemize}Statistical testing was carried out as follows: 
This data was obtained from runs on multiple artefacts. Each artefact is treated as a single run for the purpose of statistical comparison and so, the experimental description below,  the number of runs refers to the number of artefacts. For each artefact 1 repeated tests were carried out and the median of these results was used as the result for that artefact for the purposes of subsequent statistical testing.\begin{itemize}
\item{Using the process of incrementing the number of runs until the difference is statistically significant. Initially 20 experiments were run. If sigificance is not obtained from these experiments then additional experiments are run until either significance is obtained or a maximum of 100 experiments have been run. When this technique is used effect size testing is especially important as a number of samples sufficient to show a statistically significant difference is likely to be reached even if the difference is too small to be useful. Note that this strategy involves multiple P value calculations as $n$ increases. These have not been adjusted and issues related to multiple testing should be taken into account when interpreting these results.
}
\item{The data is dichotomous and paired and so the Fisher test of statistical significance was used followed by the Odds Ratio test of effect size.These tests compare boolean values, denoting a pass or a fail, from the final point in the result time series. 

This data is censored, that is to say the point at which results are obtained is the arbitrary point at which the test stopped running. This may not accurately reflect the true difference between the two datasets. For this reason, additional statistical tests were carried out if this initial test did not show significance. Additional tests where carried out in this order:
\begin{itemize}
\item{0: Tests were run using an artificial censoring point at point -1 in the time series.}
\end{itemize}Note that using these strategies involves multiple P value calculations on the same data. This should be taken into account when interpreting these results.
}
\end{itemize}A complete list of p value tests carried out is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{3}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{3}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 100. The initial censoring strategy was used (using a dichotomous test on the results at the end of the time series). 

The final results from comparing null and null are as follows:
\begin{itemize}
\item{difference is significant (p value of 0.027827254996099268, threshold of 0.05)}
\item{the effect size is 0.4779012664771259}
\item{null is lower than null}
\end{itemize}

\section{References}
\bibliographystyle{plain}

\begin{thebibliography}{99}
\bibitem{Neumann:2014:EET:2598394.2609850}
Geoffrey Neumann, Jerry Swan, Mark Harman and John A. Clark,
The Executable Experimental Template Pattern for the Systematic Comparison of Metaheuristics,
GECCO Comp '14,
2014
\bibitem{Arcuri2012}
Andrea Arcuri and Lionel Briand,
A hitchhiker's guide to statistical tests for assessing randomized algorithms in software engineering,
Software Testing, Verification and Reliability, 24 (3),
2012
\bibitem{Brunner2000}
Edgar Brunner and Ullrich Munzel, 
The Nonparametric Behrens-Fisher Problem: Asymptotic Theory and aSmall-Sample Approximation, 
Biometrical Journal, 42 (1), 
2000, 
pages 17--25
\bibitem{Gibbons2011}
Jean Dickinson Gibbons and Subhabrata Chakraborti 
Nonparametric statistical inference 
2011, 
Springer\end{thebibliography}

\end{document}
