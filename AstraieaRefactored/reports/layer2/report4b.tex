\documentclass[]{article}
\usepackage[usenames,dvipsnames]{color}
\usepackage{longtable}
\begin{document}

\section{Experimental Results (Wed Feb 17 08:56:05 GMT 2016)}
Experiments were performed using the \textsc{Astraiea}\footnote{This file has been automatically generated by Astraiea} statistical testing framework \cite{Neumann:2014:EET:2598394.2609850},
which performs tests in accordance with the guidelines of ``A Hitchhikers guide to statistical testing''
by Briand and Arcuri~\cite{Arcuri2012}.
Unless a different reference is given, the tests are performed as described in this paper.



Statistical testing was carried out as follows: 
\begin{itemize}
\item{All experiments were repeated 30 times ($n$=30)}
\item{The data is dichotomous and paired and so the Fisher test of statistical significance was used followed by the Odds Ratio test of effect size.These tests compare boolean values, denoting a pass or a fail, from the final point in the result time series. 

This data is censored, that is to say the point at which results are obtained is the arbitrary point at which the test stopped running. This may not accurately reflect the true difference between the two datasets. For this reason, additional statistical tests were carried out if this initial test did not show significance. Additional tests where carried out in this order:
\begin{itemize}
\item{0: Tests were run using a censoring point at the final point in the time series.}
\item{1: Tests were run using a non dichotomous P Value test in which the length of time taken to reach a successful result is compared("Time to Pass" test).}
\end{itemize}Note that using these strategies involves multiple P value calculations on the same data. This should be taken into account when interpreting these results.
}
\item{The points below only apply to the non dichotomous time based test:}
\item{The Wilcoxon/ Mann Whitney U Significance Test was used.}
\item{The Vargha Delaney Effect Size Test was used. Effect size testing is essential in addition to significance testing as it demonstrates the magnitude of the difference between two samples. With a large enough number of experiments (large enough $n$), the results of two different generating techniques are likely to be different to a statistically significant extent. Effect size testing is needed to show that this difference is useful.}
\end{itemize}A complete list of p values for generators test1 and test2 is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{4}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{4}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 
30&30&Censoring Point: end of run&0.4219753810198912\\

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}
30&30&Times To Pass&0.035027035062719536\\

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 30. The initial censoring strategy was used (using a dichotomous test on the results at the end of the time series). 

The final results from comparing test1 and test2 are as follows:
\begin{itemize}
\item{difference is significant (p value of 0.035027035062719536, threshold of 0.05)}
\item{the effect size is 0.6583333333333334, confidence intervals (obtained by bootstrapping)= 0.5195277777777778 - 0.7782777777777777}
\item{test1 is greater than test2}
\end{itemize}

Statistical testing was carried out as follows: 
\begin{itemize}
\item{All experiments were repeated 30 times ($n$=30)}
\item{The data is dichotomous and paired and so the Fisher test of statistical significance was used followed by the Odds Ratio test of effect size.These tests compare boolean values, denoting a pass or a fail, from the final point in the result time series. 

This data is censored, that is to say the point at which results are obtained is the arbitrary point at which the test stopped running. This may not accurately reflect the true difference between the two datasets. For this reason, additional statistical tests were carried out if this initial test did not show significance. Additional tests where carried out in this order:
\begin{itemize}
\item{0: Tests were run using a censoring point at the final point in the time series.}
\item{1: Tests were run using a non dichotomous P Value test in which the length of time taken to reach a successful result is compared("Time to Pass" test).}
\end{itemize}Note that using these strategies involves multiple P value calculations on the same data. This should be taken into account when interpreting these results.
}
\item{The points below only apply to the non dichotomous time based test:}
\item{The Brunner Munzel P Value Significance Test was used. Brunner Munzel is used in place of the  Wilcoxon/ Mann Whitney U test recommended in Arcuri's paper~\cite{Arcuri2012} because the Brunner Munzel test is tolerant of heteroscedastic data whereas the Wilcoxon/ Mann Whitney U test is not~\cite{Brunner2000}.}
\item{The Vargha Delaney Effect Size Test was used. Effect size testing is essential in addition to significance testing as it demonstrates the magnitude of the difference between two samples. With a large enough number of experiments (large enough $n$), the results of two different generating techniques are likely to be different to a statistically significant extent. Effect size testing is needed to show that this difference is useful.}
\end{itemize}A complete list of p values for generators test1 and test2 is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{4}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{4}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 
30&30&Censoring Point: end of run&0.4219753810198912\\
30&30&Times To Pass&0.027346879788939793\\

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 30. The initial censoring strategy was used (using a dichotomous test on the results at the end of the time series). 

The final results from comparing test1 and test2 are as follows:
\begin{itemize}
\item{difference is significant (p value of 0.027346879788939793, threshold of 0.05)}
\item{the effect size is 0.6583333333333334, confidence intervals (obtained by bootstrapping)= 0.5195277777777778 - 0.7782777777777777}
\item{test1 is greater than test2}
\end{itemize}
\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}


Statistical testing was carried out as follows: 
\begin{itemize}
\item{Using the process of incrementing the number of runs until the difference is statistically significant. Initially 30 experiments were run. If sigificance is not obtained from these experiments then additional experiments are run until either significance is obtained or a maximum of 100 experiments have been run. When this technique is used effect size testing is especially important as a number of samples sufficient to show a statistically significant difference is likely to be reached even if the difference is too small to be useful. Note that this strategy involves multiple P value calculations as $n$ increases. These have not been adjusted and issues related to multiple testing should be taken into account when interpreting these results.
}
\item{The Wilcoxon/ Mann Whitney U Significance Test was used.}
\item{The Vargha Delaney Effect Size Test was used. Effect size testing is essential in addition to significance testing as it demonstrates the magnitude of the difference between two samples. With a large enough number of experiments (large enough $n$), the results of two different generating techniques are likely to be different to a statistically significant extent. Effect size testing is needed to show that this difference is useful.}
\end{itemize}A complete list of p values for generators test1 and test2 is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{4}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{4}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 
30&30&Incrementing&0.02558535265900963\\

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 30. 

The final results from comparing test1 and test2 are as follows:
\begin{itemize}
\item{difference is significant (p value of 0.02558535265900963, threshold of 0.05)}
\item{the effect size is 0.3322222222222222, confidence intervals (obtained by bootstrapping)= 0.18788888888888888 - 0.4922222222222222}
\item{test1 is lower than test2}
\end{itemize}

Statistical testing was carried out as follows: 
\begin{itemize}
\item{Using the process of incrementing the number of runs until the difference is statistically significant. Initially 30 experiments were run. If sigificance is not obtained from these experiments then additional experiments are run until either significance is obtained or a maximum of 100 experiments have been run. When this technique is used effect size testing is especially important as a number of samples sufficient to show a statistically significant difference is likely to be reached even if the difference is too small to be useful. Note that this strategy involves multiple P value calculations as $n$ increases. These have not been adjusted and issues related to multiple testing should be taken into account when interpreting these results.
}
\item{The Wilcoxon/ Mann Whitney U Significance Test was used.}
\item{The Vargha Delaney Effect Size Test was used. Effect size testing is essential in addition to significance testing as it demonstrates the magnitude of the difference between two samples. With a large enough number of experiments (large enough $n$), the results of two different generating techniques are likely to be different to a statistically significant extent. Effect size testing is needed to show that this difference is useful.}
\end{itemize}A complete list of p values for generators test1 and test2 is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{4}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{4}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 
30&30&Incrementing&0.19324837891878432\\

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}
60&60&Incrementing&0.012757099293450036\\

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 60. 

The final results from comparing test1 and test2 are as follows:
\begin{itemize}
\item{difference is significant (p value of 0.012757099293450036, threshold of 0.05)}
\item{the effect size is 0.3680555555555556, confidence intervals (obtained by bootstrapping)= 0.2636388888888889 - 0.46856944444444437}
\item{test1 is lower than test2}
\end{itemize}
\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}


Statistical testing was carried out as follows: 
\begin{itemize}
\item{All experiments were repeated 30 times ($n$=30)}
\item{The data is dichotomous and paired and so the Fisher test of statistical significance was used followed by the Odds Ratio test of effect size.These tests compare boolean values, denoting a pass or a fail, from the final point in the result time series. }
\end{itemize}
The final results from comparing test1 and test2 are as follows:
\begin{itemize}
\item{difference is significant (p value of 9.162440773562147E-4, threshold of 0.05)}
\item{the effect size is 0.13099730458221023}
\item{test1 is lower than test2}
\end{itemize}

Statistical testing was carried out as follows: 
\begin{itemize}
\item{All experiments were repeated 30 times ($n$=30)}
\item{The data is dichotomous and paired and so the Fisher test of statistical significance was used followed by the Odds Ratio test of effect size.These tests compare boolean values, denoting a pass or a fail, from the final point in the result time series. 

This data is censored, that is to say the point at which results are obtained is the arbitrary point at which the test stopped running. This may not accurately reflect the true difference between the two datasets. For this reason, additional statistical tests were carried out if this initial test did not show significance. Additional tests where carried out in this order:
\begin{itemize}
\item{0: Tests were run using a censoring point at the final point in the time series.}
\item{1: Tests were run using a censoring point at point 50 in the time series.}
\end{itemize}Note that using these strategies involves multiple P value calculations on the same data. This should be taken into account when interpreting these results.
}
\end{itemize}A complete list of p values for generators test1 and test2 is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{4}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{4}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 
30&30&Censoring Point: end of run&0.4219753810198912\\
30&30&Censoring Point: 50&0.9999999999999929\\

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 30. The initial censoring strategy was used (using a dichotomous test on the results at the end of the time series). 

The final results from comparing test1 and test2 are as follows:
\begin{itemize}
\item{data is not significant (p value of 0.9999999999999929, threshold of 0.05)}
\end{itemize}

Statistical testing was carried out as follows: 
\begin{itemize}
\item{Using the process of incrementing the number of runs until the difference is statistically significant. Initially 20 experiments were run. If sigificance is not obtained from these experiments then additional experiments are run until either significance is obtained or a maximum of 100 experiments have been run. When this technique is used effect size testing is especially important as a number of samples sufficient to show a statistically significant difference is likely to be reached even if the difference is too small to be useful. Note that this strategy involves multiple P value calculations as $n$ increases. These have not been adjusted and issues related to multiple testing should be taken into account when interpreting these results.
}
\item{The Wilcoxon/ Mann Whitney U Significance Test was used.}
\item{The Vargha Delaney Effect Size Test was used. Effect size testing is essential in addition to significance testing as it demonstrates the magnitude of the difference between two samples. With a large enough number of experiments (large enough $n$), the results of two different generating techniques are likely to be different to a statistically significant extent. Effect size testing is needed to show that this difference is useful.}
\end{itemize}A complete list of p values for generators test1 and test2 is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{4}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{4}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 
20&20&Incrementing&0.49888051907411923\\

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}
40&40&Incrementing&0.2576091100813128\\

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}
60&60&Incrementing&0.5339657379759071\\

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}
80&80&Incrementing&0.0739271203226528\\

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}
100&100&Incrementing&0.006174550948616964\\

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 100. 

The final results from comparing test1 and test2 are as follows:
\begin{itemize}
\item{difference is significant (p value of 0.006174550948616964, threshold of 0.05)}
\item{the effect size is 0.3879, confidence intervals (obtained by bootstrapping)= 0.30995 - 0.468695}
\item{test1 is lower than test2}
\end{itemize}
\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}

\textcolor{Red}{WARNING: Since the data contains ties or zeros, a non exact version of the Mann Whitney U test was used
}


Statistical testing was carried out as follows: 
\begin{itemize}
\item{Using the process of incrementing the number of runs until the difference is statistically significant. Initially 20 experiments were run. If sigificance is not obtained from these experiments then additional experiments are run until either significance is obtained or a maximum of 100 experiments have been run. When this technique is used effect size testing is especially important as a number of samples sufficient to show a statistically significant difference is likely to be reached even if the difference is too small to be useful. Note that this strategy involves multiple P value calculations as $n$ increases. These have not been adjusted and issues related to multiple testing should be taken into account when interpreting these results.
}
\item{The data is dichotomous and paired and so the Fisher test of statistical significance was used followed by the Odds Ratio test of effect size.These tests compare boolean values, denoting a pass or a fail, from the final point in the result time series. }
\end{itemize}A complete list of p values for generators test1 and test2 is shown in table~\ref{p value tests}, with $n$ corresponding to the number of samples in each data set.
\begin{center}
\begin{longtable}{|l|l|l|l|}
\caption[P Value Tests]{P Value Tests} \label{p value tests} \\ 
\hline \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\\ \hline 
\endfirsthead 
\multicolumn{4}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ 
 \hline 
 \multicolumn{1}{|c|}{\textbf{n for test1}} &  \multicolumn{1}{|c|}{\textbf{n for test2}} &  \multicolumn{1}{|c|}{\textbf{Notes}} &  \multicolumn{1}{|c|}{\textbf{P-Value}}
\endhead 
\hline \multicolumn{4}{|r|}{{Continued on next page}} \\ \hline 
\endfoot 
\hline 
\endlastfoot 
20&20&Incrementing&0.32026576075518975\\
40&40&Incrementing&0.47434051828682\\
60&60&Incrementing&0.4220205562868679\\
80&80&Incrementing&0.22123219594994134\\
100&100&Incrementing&0.027827254996099268\\

\hline
\end{longtable}
\end{center}

The final test, and the test on which effect size was calculated, was carried out using an $n$ of 100. 

The final results from comparing test1 and test2 are as follows:
\begin{itemize}
\item{difference is significant (p value of 0.027827254996099268, threshold of 0.05)}
\item{the effect size is 0.4779012664771259}
\item{test1 is lower than test2}
\end{itemize}

\section{References}
\bibliographystyle{plain}

\begin{thebibliography}{99}
\bibitem{Neumann:2014:EET:2598394.2609850}
Geoffrey Neumann, Jerry Swan, Mark Harman and John A. Clark,
The Executable Experimental Template Pattern for the Systematic Comparison of Metaheuristics,
GECCO Comp '14,
2014
\bibitem{Arcuri2012}
Andrea Arcuri and Lionel Briand,
A hitchhiker's guide to statistical tests for assessing randomized algorithms in software engineering,
Software Testing, Verification and Reliability, 24 (3),
2012
\bibitem{Brunner2000}
Edgar Brunner and Ullrich Munzel, 
The Nonparametric Behrens-Fisher Problem: Asymptotic Theory and aSmall-Sample Approximation, 
Biometrical Journal, 42 (1), 
2000, 
pages 17--25
\bibitem{Gibbons2011}
Jean Dickinson Gibbons and Subhabrata Chakraborti 
Nonparametric statistical inference 
2011, 
Springer\bibitem{Neumann2015}
Geoffrey Neumann, Mark Harman and Simon Poulding 
Transformed Vargha Delaney Effect Size 
Lecture Notes in Computer Science 
SSBSE 
2015, 
pages 318--324
\end{thebibliography}

\end{document}
